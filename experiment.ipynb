{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data analysis stage:\n",
    "#### 1. Join the data\n",
    "#### 2. Research ways to analyse how each of the features affects the probability of a transaction to be fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet2520\\AppData\\Local\\Temp\\ipykernel_11336\\2353394586.py:3: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv('dataset/model_dataset/transactions_train.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'IS_RECURRING_TRANSACTION' cleaned and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('dataset/model_dataset/transactions_train.csv')\n",
    "column_name = 'IS_RECURRING_TRANSACTION'\n",
    "\n",
    "def clean_column(value):\n",
    "    if value is True:\n",
    "        return \"True\"\n",
    "    elif (value is False) or (value==\"Fals\"):\n",
    "        return \"False\"\n",
    "    return str(value)\n",
    "\n",
    "# Apply the function to the column\n",
    "df_train[column_name] = df_train[column_name].apply(clean_column)\n",
    "\n",
    "df_train.to_csv('dataset/model_dataset/transactions_train.csv', index=False)\n",
    "\n",
    "print(f\"Column '{column_name}' cleaned and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet2520\\AppData\\Local\\Temp\\ipykernel_11336\\4166422411.py:3: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset/model_dataset/full_transactions_train.csv')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('dataset/model_dataset/full_transactions_train.csv')\n",
    "\n",
    "df['CUST_TO_TERM_DIST'] = np.sqrt((df['x_terminal_id'] - df['x_customer_id']) ** 2 +\n",
    "                                  (df['y_terminal__id'] - df['y_customer_id']) ** 2)\n",
    "df.drop(columns=['x_customer_id', 'y_customer_id', 'x_terminal_id', 'y_terminal__id', 'CUSTOMER_ID', 'TERMINAL_ID'], inplace=True)\n",
    "df.to_csv('cleaned_file_with_distances.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet2520\\AppData\\Local\\Temp\\ipykernel_11336\\2328511768.py:3: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('cleaned_file_with_distances.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TX_ID', 'TX_TS', 'TX_AMOUNT', 'TX_FRAUD',\n",
      "       'TRANSACTION_GOODS_AND_SERVICES_AMOUNT', 'TRANSACTION_CASHBACK_AMOUNT',\n",
      "       'CARD_EXPIRY_DATE', 'CARD_DATA', 'CARD_BRAND', 'TRANSACTION_TYPE',\n",
      "       'TRANSACTION_STATUS', 'FAILURE_CODE', 'FAILURE_REASON',\n",
      "       'TRANSACTION_CURRENCY', 'CARD_COUNTRY_CODE', 'MERCHANT_ID',\n",
      "       'IS_RECURRING_TRANSACTION', 'ACQUIRER_ID', 'CARDHOLDER_AUTH_METHOD',\n",
      "       'BUSINESS_TYPE', 'MCC_CODE', 'LEGAL_NAME', 'FOUNDATION_DATE',\n",
      "       'TAX_EXCEMPT_INDICATOR', 'OUTLET_TYPE', 'ACTIVE_FROM', 'TRADING_FROM',\n",
      "       'ANNUAL_TURNOVER_CARD', 'ANNUAL_TURNOVER', 'AVERAGE_TICKET_SALE_AMOUNT',\n",
      "       'PAYMENT_PERCENTAGE_FACE_TO_FACE', 'PAYMENT_PERCENTAGE_ECOM',\n",
      "       'PAYMENT_PERCENTAGE_MOTO', 'DEPOSIT_REQUIRED_PERCENTAGE',\n",
      "       'DEPOSIT_PERCENTAGE', 'DELIVERY_SAME_DAYS_PERCENTAGE',\n",
      "       'DELIVERY_WEEK_ONE_PERCENTAGE', 'DELIVERY_WEEK_TWO_PERCENTAGE',\n",
      "       'DELIVERY_OVER_TWO_WEEKS_PERCENTAGE', 'CUST_TO_TERM_DIST'],\n",
      "      dtype='object')\n",
      "   CUST_TO_TERM_DIST\n",
      "0           2.727257\n",
      "1           2.550229\n",
      "2           3.850495\n",
      "3           2.889452\n",
      "4           3.829107\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_file_with_distances.csv')\n",
    "print(df.columns)  # Check if the new column exists in the saved CSV\n",
    "print(df[['CUST_TO_TERM_DIST']].head())\n",
    "#full_t_train = pd.read_csv('dataset/model_dataset/full_transactions_train.csv', index_col='TX_ID')\n",
    "#full_t_test = pd.read_csv('dataset/model_dataset/full_transactions_test.csv', index_col='TX_ID')\n",
    "#transactions_train = pd.read_csv('dataset/model_dataset/transactions_train.csv')\n",
    "#transactions_test = pd.read_csv('dataset/model_dataset/transactions_test.csv')\n",
    "#customers = pd.read_csv('dataset/model_dataset/customers.csv', index_col='CUSTOMER_ID')\n",
    "#merchants = pd.read_csv('dataset/model_dataset/merchants.csv', index_col='MERCHANT_ID')\n",
    "#terminals = pd.read_csv('dataset/model_dataset/terminals.csv', index_col='TERMINAL_ID')\n",
    "##Merge transactions with customers on 'customer_id'\n",
    "#transactions_with_customers = pd.merge(transactions_train, customers, on='CUSTOMER_ID', how='left')\n",
    "#transactions_with_customers_terminals = pd.merge(transactions_with_customers, terminals, on='TERMINAL_ID', how='left')\n",
    "#full_transactions = pd.merge(transactions_with_customers_terminals, merchants, on='MERCHANT_ID', how='left')\n",
    "#print(full_transactions.head())\n",
    "#full_transactions.to_csv('dataset/model_dataset/full_transactions_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAILURE_CODE', 'FAILURE_REASON', 'ACQUIRER_ID', 'CARDHOLDER_AUTH_METHOD']\n"
     ]
    }
   ],
   "source": [
    "cols_missing = [col for col in df.columns if df[col].isnull().any()]\n",
    "print(cols_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TX_ID', 'TX_TS', 'TX_AMOUNT', 'TRANSACTION_GOODS_AND_SERVICES_AMOUNT',\n",
      "       'TRANSACTION_CASHBACK_AMOUNT', 'CARD_EXPIRY_DATE', 'CARD_DATA',\n",
      "       'CARD_BRAND', 'TRANSACTION_TYPE', 'TRANSACTION_STATUS',\n",
      "       'TRANSACTION_CURRENCY', 'CARD_COUNTRY_CODE', 'MERCHANT_ID',\n",
      "       'IS_RECURRING_TRANSACTION', 'BUSINESS_TYPE', 'MCC_CODE', 'LEGAL_NAME',\n",
      "       'FOUNDATION_DATE', 'TAX_EXCEMPT_INDICATOR', 'OUTLET_TYPE',\n",
      "       'ACTIVE_FROM', 'TRADING_FROM', 'ANNUAL_TURNOVER_CARD',\n",
      "       'ANNUAL_TURNOVER', 'AVERAGE_TICKET_SALE_AMOUNT',\n",
      "       'PAYMENT_PERCENTAGE_FACE_TO_FACE', 'PAYMENT_PERCENTAGE_ECOM',\n",
      "       'PAYMENT_PERCENTAGE_MOTO', 'DEPOSIT_REQUIRED_PERCENTAGE',\n",
      "       'DEPOSIT_PERCENTAGE', 'DELIVERY_SAME_DAYS_PERCENTAGE',\n",
      "       'DELIVERY_WEEK_ONE_PERCENTAGE', 'DELIVERY_WEEK_TWO_PERCENTAGE',\n",
      "       'DELIVERY_OVER_TWO_WEEKS_PERCENTAGE', 'CUST_TO_TERM_DIST'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "df.dropna(axis=0, subset=['TX_FRAUD'], inplace=True)\n",
    "y = df.TX_FRAUD\n",
    "df.drop(['TX_FRAUD'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "df.drop(cols_missing, axis=1, inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    print(preds)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "[0.03 0.   0.14 ... 0.1  0.   0.01]\n",
      "0.03328527624620232\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4929********693' '4916********991' '5551********560' ...\n",
      " '3427********767' '3409********256' '3777********251']\n",
      "['4916********912' '4929********541' '4485********231' ...\n",
      " '3409********546' '3409********103' '3427********751']\n",
      "\n",
      "['Visa' 'MasterCard' 'AMEX' 'Discover']\n",
      "['Visa' 'AMEX' 'MasterCard' 'Discover']\n",
      "\n",
      "['Refund' 'Purchase' 'Purchase\\xa0with\\xa0cashback'\n",
      " 'Cash\\xa0Advance/Withdrawal']\n",
      "['Purchase' 'Cash\\xa0Advance/Withdrawal' 'Purchase\\xa0with\\xa0cashback'\n",
      " 'Refund']\n",
      "\n",
      "['Settled' 'Captured' 'Rejected' 'Authorized']\n",
      "['Settled' 'Captured' 'Authorized' 'Rejected']\n",
      "\n",
      "['GBP' 'EUR' 'CHF' 'CNY' 'CAD' 'JPY' 'USD' 'AED' 'RON' 'HKD' 'MDL']\n",
      "['GBP' 'EUR' 'HKD' 'USD' 'CHF' 'CNY' 'JPY' 'CAD' 'RON' 'AED' 'MDL']\n",
      "\n",
      "['GB' 'BE' 'US' 'DE' 'CA' 'AE' 'FR' 'NO' 'HR' 'DK' 'RO' 'FI' 'BT' 'SA']\n",
      "['GB' 'BE' 'US' 'RO' 'NO' 'FR' 'DE' 'HR' 'DK' 'CA' 'SA' 'BT' 'FI' 'AE']\n",
      "\n",
      "[False True 'False' 'True' 'Fals']\n",
      "[False True 'False' 'True']\n",
      "\n",
      "['S Corporations' 'Sole Proprietorships' 'Limited Liability Company (LLC)'\n",
      " 'Corporations']\n",
      "['Sole Proprietorships' 'Limited Liability Company (LLC)' 'Corporations'\n",
      " 'S Corporations']\n",
      "\n",
      "['b533c8' 'd33d7d' 'fdcde2' ... '5ea02c' '0b04b4' '1307ad']\n",
      "['ddca55' '160856' '33e90e' ... '0e1c03' '2008f7' '263fee']\n",
      "\n",
      "[False  True]\n",
      "[False  True]\n",
      "\n",
      "['Face to Face' 'Face to Face and Ecommerce' 'Ecommerce']\n",
      "['Face to Face' 'Ecommerce' 'Face to Face and Ecommerce']\n",
      "\n",
      "[3.65660621 1.06596189 2.84903139 ... 2.94974787 3.57145581 2.00325305]\n",
      "[3.34314724 4.67916627 2.9148254  ... 3.53723483 2.64682562 4.74113553]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(X_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# ts_tx can't use ordinal/one-hot encoding\n",
    "# card_expiry_date can't use ordninal/one-hot encoding\n",
    "# merchant_id can't use ordninal/one-hot encoding\n",
    "\n",
    "cols = ['CARD_DATA',\n",
    "       'CARD_BRAND', 'TRANSACTION_TYPE', 'TRANSACTION_STATUS',\n",
    "       'TRANSACTION_CURRENCY', 'CARD_COUNTRY_CODE',\n",
    "       'IS_RECURRING_TRANSACTION', 'BUSINESS_TYPE', 'LEGAL_NAME',\n",
    "       'TAX_EXCEMPT_INDICATOR', 'OUTLET_TYPE',\n",
    "       'CUST_TO_TERM_DIST']\n",
    "\n",
    "for col in cols:\n",
    "  print(X_train[col].unique())\n",
    "  print(X_valid[col].unique())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['CARD_EXPIRY_DATE', 'CARD_BRAND', 'TRANSACTION_TYPE', 'TRANSACTION_STATUS', 'TRANSACTION_CURRENCY', 'CARD_COUNTRY_CODE']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['TX_TS', 'TX_ID', 'CARD_DATA']\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if\n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "\n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "\n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "[0.03 0.   0.07 ... 0.05 0.01 0.03]\n",
      "0.03744805146093545\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\")\n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
